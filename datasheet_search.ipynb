{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain duckduckgo-search\n",
    "# pip install langchain-google-community\n",
    "# pip install pip-system-certs\n",
    "# pip install -qU duckduckgo-search langchain-community\n",
    "import os\n",
    "cwd_path = os.getcwd()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from openai import AzureOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain import tools\n",
    "from langchain_core.tools import tool, Tool\n",
    "import langchain_community\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent, initialize_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "import requests\n",
    "# from langchain_community.document_loaders import WebBaseLoader, OnlinePDFLoader\n",
    "# from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from googlesearch import search\n",
    "from PyPDF2 import PdfReader\n",
    "from pathlib import Path\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT = os.environ['OPENAI_ENDPOINT']\n",
    "API_KEY = os.environ['OPENAI_API_KEY']\n",
    "AZURE_DEPLOYMENT = os.environ['AZURE_DEPLOYMENT']\n",
    "AZURE_OPENAI_VERSION = os.environ['AZURE_OPENAI_VERSION']\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=ENDPOINT,\n",
    "    openai_api_key=API_KEY,\n",
    "    azure_deployment=AZURE_DEPLOYMENT,\n",
    "    openai_api_version=AZURE_OPENAI_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def SearchWebForPdf(query):\n",
    "    \"\"\" Search for pdf dataset in the web. Return list of urls of pdf documents. The input\n",
    "    to the tool will be a query text to perform the search of the datasheet. For example, if\n",
    "    query is 'lm741 datasheet pdf' then you need to return all the links of the search results\n",
    "    in a format of list. For example, if there are 3 search results of Link1, Link2 and Link3, \n",
    "    then this function should return [Link1, Link2, Link3]\n",
    "    \"\"\" \n",
    "    result = search(query, tld=\"co.in\", num=2, stop=2, pause=2)\n",
    "    search_list =[]\n",
    "    for j in result:\n",
    "        search_list.append(j)\n",
    "    return search_list\n",
    "\n",
    "@tool\n",
    "def DownloadFileTool(search_list):\n",
    "    \"\"\"Downloads top pdf files from URLs and saves it to a specified path. The input\n",
    "    to the tool will be a list of links. All the links will be checked one by one if the link \n",
    "    contains pdf file or not. If the link type is pdf, then it will download the pdf\n",
    "    file at a specified location in local disk\"\"\"\n",
    "    \n",
    "    failed_file = 0\n",
    "    file_number = 1\n",
    "    for url in search_list:    \n",
    "        try:\n",
    "            response = requests.get(url, stream=True)\n",
    "            response.raise_for_status()  # Raise an exception for bad status codes\n",
    "            \n",
    "            # Check if the content type is PDF\n",
    "            if 'application/pdf' not in response.headers.get('content-type', '').lower():\n",
    "                print(\"Error: URL does not point to a PDF file.\")\n",
    "                failed_file+=1\n",
    "            else:\n",
    "                dwnld_path = cwd_path+\"\\Datasheet_Folder\"\n",
    "                if not os.path.exists(dwnld_path):\n",
    "                    os.makedirs(dwnld_path)\n",
    "                file_name = dwnld_path+\"\\datasheet_pdf_\"+str(file_number) + \".pdf\"\n",
    "                with open(file_name, 'wb') as pdf_file:\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        pdf_file.write(chunk)\n",
    "                print(f\"File downloaded successfully\")\n",
    "                file_number+=1\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error downloading file: {e}\")\n",
    "            failed_file+=1\n",
    "    if(failed_file==len(search_list)):\n",
    "        print (\"No pdf file is found downloadable\")\n",
    "        return error\n",
    "    else:\n",
    "        print (\"pdf file(s)) saved successfully\")\n",
    "        return dwnld_path\n",
    "@tool\n",
    "# Get the pdf file list\n",
    "def get_pdf_files(folder_path):\n",
    "    \"\"\"\n",
    "    Retrieves a list of PDF file paths from a specified folder.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder to search.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Path objects representing the PDF files found.\n",
    "    \"\"\"\n",
    "    folder = Path(folder_path)\n",
    "    pdf_files = list(folder.glob(\"*.pdf\"))  # Finds all .pdf files in the immediate folder\n",
    "    return pdf_files\n",
    "\n",
    "@tool\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PdfReader(file)\n",
    "            for page_num in range(len(reader.pages)):\n",
    "                text += reader.pages[page_num].extract_text()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text: {e}\")\n",
    "    return text\n",
    "\n",
    "@tool\n",
    "def classify_document_with_openai(pdf_path, text_content, microchip_name):\n",
    "    \"\"\"Classifies the document using Azure OpenAI.\"\"\"\n",
    "    client = AzureOpenAI(\n",
    "        api_key=API_KEY,\n",
    "        azure_endpoint=ENDPOINT,\n",
    "        api_version=AZURE_OPENAI_VERSION\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"Analyze the following document text and determine if it is a datasheet for the microchip '{microchip_name}'.\n",
    "    A microchip datasheet typically includes details like:\n",
    "    - Electrical characteristics (voltage, current, frequency)\n",
    "    - Pin configurations and descriptions\n",
    "    - Operating conditions and environmental ratings\n",
    "    - Package dimensions and types\n",
    "    - Block diagrams or functional diagrams\n",
    "    - Part numbers and ordering information\n",
    "    - Application notes or typical usage circuits.\n",
    "\n",
    "    Based on these criteria, is this document a microchip datasheet? Respond with 'YES' or 'NO' and a brief explanation.\n",
    "\n",
    "    Document Text:\n",
    "    {text_content[:8000]} # Truncate for very large documents if needed\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=AZURE_DEPLOYMENT,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert document classifier.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=150\n",
    "    )\n",
    "    file_name = str(pdf_path).split('/')[-1]\n",
    "    if('**NO**' in response.choices[0].message.content):\n",
    "        print(f\"{file_name} is not the datasheet\")\n",
    "    if('**YES**' in response.choices[0].message.content):\n",
    "        print(f\"{file_name} is the datasheet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [SearchWebForPdf,DownloadFileTool,get_pdf_files,extract_text_from_pdf,classify_document_with_openai]\n",
    "random.shuffle(tools)\n",
    "system_message = \"\"\"\n",
    "You are a web search and datasheet validation agent. Your job is to search and download datasheets in pdf for a specified\n",
    "components and then read them from a folder and validate how many of them are valid datasheet. You have five helper functions \n",
    "'SearchWebForPdf', 'DownloadFileTool', 'get_pdf_files', 'extract_text_from_pdf' and 'classify_document_with_openai'. \n",
    "'SearchWebForPdf' will help you to get the all list of urls related to the human query. 'DownloadFileTool' will help you \n",
    "to download all valid pdfs from the list one by one and store in local disk in a specified location. 'get_pdf_files' will \n",
    "help to get the list of all pdf files from the targeted folder. 'extract_text_from_pdf' will help to get the content of \n",
    "pdf file into text format. Finally, 'classify_document_with_openai' will help to decide if a pdf file is the datasheet or not.\n",
    "While calling 'classify_document_with_openai', you need to pass the microchip name from the human query message as one of the\n",
    "parameters.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_message),\n",
    "        # MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ])\n",
    "\n",
    "# initializing the agent\n",
    "# agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "# agent = create_tool_calling_agent(model, tools, prompt)\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "human_query = '''\n",
    "can you do google search and download datasheet of LF260 and verify if the downloaded file(s) is the datasheet of LF260? \n",
    "Do not print anything on the console unless printed by agent. \n",
    "'''\n",
    "# Input with tool calls\n",
    "messages = [\n",
    "    (\"user\", human_query)\n",
    "]\n",
    "\n",
    "result = agent_executor.invoke({\"input\": messages})\n",
    "# result = agent.run(human_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasheet_pdf_1.pdf is not the datasheet\n",
      "datasheet_pdf_2.pdf is not the datasheet\n",
      "datasheet_pdf_3.pdf is not the datasheet\n",
      "datasheet_pdf_4.pdf is not the datasheet\n",
      "datasheet_pdf_5.pdf is not the datasheet\n",
      "datasheet_pdf_6.pdf is not the datasheet\n",
      "datasheet_pdf_7.pdf is not the datasheet\n",
      "datasheet_pdf_8.pdf is not the datasheet\n"
     ]
    }
   ],
   "source": [
    "pdf_list = get_pdf_files(dwld_path)\n",
    "for element in pdf_list:\n",
    "    file_content = extract_text_from_pdf(element)\n",
    "    classify_document_with_openai(element, file_content, 'LCO 7A chip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = classify_document_with_openai(pdf_file_exmple,'LCO 7A chip')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
